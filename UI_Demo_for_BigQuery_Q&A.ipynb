{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UEv34vVKxR9k",
        "aPh6goEQyKsD",
        "LqDhLithzJgd",
        "mpW-rMVI0DUZ",
        "LAlVAHPe16Xr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BigQuery Q&A using langchain & LLM (go/ask-bigquery)**\n"
      ],
      "metadata": {
        "id": "nWKmZBiRSbO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo: This notebook guides you on use of LLM to answer questions over a BigQuery table.\n",
        "This notebook has also been tested on big datasets(~2 million rows) and works well with low latency.\n",
        "\n",
        "Dataset: Fitbit public dataset from Kaggle (https://www.kaggle.com/datasets/arashnic/fitbit)\n",
        "\n",
        "To use it on your own data, change the parameters in the section \"App parameters initialization\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "|Author:       |Nikhil Rana (nikhilrana@)|\n",
        "|--------------|---------|\n",
        "|Last Updated: |5/30/2023|\n",
        "\n",
        "\n",
        "Example input: What is the average number of steps taken by the user?"
      ],
      "metadata": {
        "id": "j9BPkBzhTDzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Date     | Change Log  |\n",
        "|----------|-------------|\n",
        "|5/17/2023 |Added Gradio UI at the end |\n",
        "|5/23/2023 |Changed setup to latest SDK|\n",
        "|5/30/2023 |Modified Prompt template for metadata queries|\n",
        "|5/31/2023 |Successfully tested on multiple SQL joins|\n",
        "|5/31/2023 |Modified prompt template for casting data types for calculations|\n",
        "|6/07/2023 |Updated SDKs to latest Langchain & SQLAlchemy|"
      ],
      "metadata": {
        "id": "6oFGVUMTJnih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install latest Vertex LLM SDK"
      ],
      "metadata": {
        "id": "UEv34vVKxR9k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DtJU7su79db8"
      },
      "outputs": [],
      "source": [
        "# Authenticate with Google account\n",
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for latest available SDK\n",
        "# !gsutil cp gs://vertex_sdk_llm_private_releases/SDK/google_cloud_aiplatform-1.23.0.llm.alpha.23.03.28-py2.py3-none-any.whl .\n",
        "# !gsutil cp gs://vertex_sdk_llm_private_releases/SDK/google_cloud_aiplatform-1.25.dev20230502+language.models-py2.py3-none-any.whl .\n",
        "\n",
        "!pip3 uninstall -y google-cloud-aiplatform\n",
        "!!pip install google-cloud-aiplatform --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lzgVKo1I9h30",
        "outputId": "1333ca79-7a42-4650-e2c7-a19931cd467a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping google-cloud-aiplatform as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting google-cloud-aiplatform',\n",
              " '  Downloading google_cloud_aiplatform-1.35.0-py2.py3-none-any.whl (3.1 MB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/3.1 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.1/3.1 MB\\x1b[0m \\x1b[31m2.6 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.9/3.1 MB\\x1b[0m \\x1b[31m12.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m3.1/3.1 MB\\x1b[0m \\x1b[31m33.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m3.1/3.1 MB\\x1b[0m \\x1b[31m27.0 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)',\n",
              " 'Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.22.3)',\n",
              " 'Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)',\n",
              " 'Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.2)',\n",
              " 'Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)',\n",
              " 'Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.12.0)',\n",
              " 'Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.10.4)',\n",
              " 'Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.2)',\n",
              " 'Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.61.0)',\n",
              " 'Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)',\n",
              " 'Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.31.0)',\n",
              " 'Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.59.0)',\n",
              " 'Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)',\n",
              " 'Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)',\n",
              " 'Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.6.0)',\n",
              " 'Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)',\n",
              " 'Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)',\n",
              " 'Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.23.5)',\n",
              " 'Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.1)',\n",
              " 'Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)',\n",
              " 'Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)',\n",
              " 'Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)',\n",
              " 'Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.3.0)',\n",
              " 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.7)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.7.22)',\n",
              " 'Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.0)',\n",
              " 'Installing collected packages: google-cloud-aiplatform',\n",
              " 'Successfully installed google-cloud-aiplatform-1.35.0']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install google_cloud_aiplatform-1.25.dev20230502+language.models-py2.py3-none-any.whl \"shapely<2.0.0\""
      ],
      "metadata": {
        "id": "DnuxDVk89nc1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python libraries setup"
      ],
      "metadata": {
        "id": "aPh6goEQyKsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Python Libraries\n",
        "!pip install chromadb --quiet\n",
        "!pip install langchain==0.0.191 --quiet\n",
        "!pip install google-cloud-core --quiet\n",
        "!pip install gradio --quiet\n",
        "\n",
        "# Below libraries are required to build a SQL engine for BigQuery\n",
        "!pip install SQLAlchemy --quiet\n",
        "!pip install sqlalchemy-bigquery --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKgtvZFD9vIQ",
        "outputId": "a25cdb00-d649-4e20-c477-956c095a7376"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.49 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exit()"
      ],
      "metadata": {
        "id": "_p0X85UA3aSa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Since the kernel restarted at this point, run the below code individually**"
      ],
      "metadata": {
        "id": "HBQjT-kZOLPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLM Model Initialization & App parameters initialization"
      ],
      "metadata": {
        "id": "aDJshtqgxlsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Specify Project details and location of the BQ table\n",
        "\n",
        "project_id = \"cheese-389814\"  # @param {type:\"string\"}\n",
        "location = \"us-central1\"  # @param {type:\"string\"}\n",
        "dataset_id = 'bestsellers' # @param {type:\"string\"}\n",
        "table_name1 = 'bestsellers_ES_limit_1M' # @param {type:\"string\"}\n",
        "table_name2 = '' # @param {type:\"string\"}\n",
        "table_name3 = '' # @param {type:\"string\"}\n",
        "\n",
        "# table_names = (table_name1,table_name2,table_name3)\n",
        "table_names = (table_name1)"
      ],
      "metadata": {
        "id": "o6eipz3LxgtE",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Vertex AI LLM wrapper for using with Langchain\n",
        "# Credits:\n",
        "#  pmarlow@: go/vertex-on-langchain-source\n",
        "# Note:\n",
        "# - 04/19: Eventually this will be replaced by Langchain + Vertex AI integration\n",
        "\n",
        "import vertexai\n",
        "vertexai.init(project=project_id, location=location)\n",
        "\n",
        "import time\n",
        "from typing import Any, Mapping, List, Dict, Optional, Tuple\n",
        "\n",
        "from pydantic import BaseModel, Extra, root_validator\n",
        "\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.chat_models.base import BaseChatModel\n",
        "from langchain.llms.utils import enforce_stop_tokens\n",
        "from langchain.schema import Generation, LLMResult\n",
        "from langchain.schema import AIMessage, BaseMessage, ChatGeneration, ChatResult, HumanMessage, SystemMessage\n",
        "\n",
        "from vertexai.preview.language_models import TextGenerationModel, TextEmbeddingModel, ChatModel\n",
        "\n",
        "\n",
        "def rate_limit(max_per_minute):\n",
        "  period = 60 / max_per_minute\n",
        "  while True:\n",
        "    before = time.time()\n",
        "    yield\n",
        "    after = time.time()\n",
        "    elapsed = after - before\n",
        "    sleep_time = max(0, period - elapsed)\n",
        "    if sleep_time > 0:\n",
        "      print(f'Sleeping {sleep_time:.1f} seconds')\n",
        "      time.sleep(sleep_time)\n",
        "\n",
        "\n",
        "class _VertexCommon(BaseModel):\n",
        "    \"\"\"Wrapper around Vertex AI large language models.\n",
        "\n",
        "    \"\"\"\n",
        "    client: Any = None #: :meta private:\n",
        "    model_name: str = \"text-bison@001\"\n",
        "    \"\"\"Model name to use.\"\"\"\n",
        "\n",
        "    temperature: float = 0.2\n",
        "    \"\"\"What sampling temperature to use.\"\"\"\n",
        "\n",
        "    top_p: int = 0.8\n",
        "    \"\"\"Total probability mass of tokens to consider at each step.\"\"\"\n",
        "\n",
        "    top_k: int = 40\n",
        "    \"\"\"The number of highest probability tokens to keep for top-k filtering.\"\"\"\n",
        "\n",
        "    max_output_tokens: int = 200\n",
        "    \"\"\"The maximum number of tokens to generate in the completion.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def _default_params(self) -> Mapping[str, Any]:\n",
        "        \"\"\"Get the default parameters for calling Vertex AI API.\"\"\"\n",
        "        return {\n",
        "            \"temperature\": self.temperature,\n",
        "            \"top_p\": self.top_p,\n",
        "            \"top_k\": self.top_k,\n",
        "            \"max_output_tokens\": self.max_output_tokens\n",
        "        }\n",
        "\n",
        "    def _predict(self, prompt: str, stop: Optional[List[str]]) -> str:\n",
        "        res = self.client.predict(prompt, **self._default_params)\n",
        "        return self._enforce_stop_words(res.text, stop)\n",
        "\n",
        "    def _enforce_stop_words(self, text: str, stop: Optional[List[str]]) -> str:\n",
        "        if stop:\n",
        "            return enforce_stop_tokens(text, stop)\n",
        "        return text\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"Return type of llm.\"\"\"\n",
        "        return \"vertex_ai\"\n",
        "\n",
        "class VertexLLM(_VertexCommon, LLM):\n",
        "    model_name: str = \"text-bison@001\"\n",
        "\n",
        "    @root_validator()\n",
        "    def validate_environment(cls, values: Dict) -> Dict:\n",
        "        \"\"\"Validate that the python package exists in environment.\"\"\"\n",
        "\n",
        "        try:\n",
        "            values[\"client\"] = TextGenerationModel.from_pretrained(values[\"model_name\"])\n",
        "        except AttributeError:\n",
        "            raise ValueError(\n",
        "                \"Could not set Vertex Text Model client.\"\n",
        "            )\n",
        "\n",
        "        return values\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        \"\"\"Call out to Vertex AI's create endpoint.\n",
        "\n",
        "        Args:\n",
        "            prompt: The prompt to pass into the model.\n",
        "\n",
        "        Returns:\n",
        "            The string generated by the model.\n",
        "        \"\"\"\n",
        "        return self._predict(prompt, stop)\n",
        "\n",
        "\n",
        "class _VertexChatCommon(_VertexCommon):\n",
        "    \"\"\"Wrapper around Vertex AI Chat large language models.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    model_name: str = \"chat-bison@001\"\n",
        "    \"\"\"Model name to use.\"\"\"\n",
        "\n",
        "    @root_validator()\n",
        "    def validate_environment(cls, values: Dict) -> Dict:\n",
        "        \"\"\"Validate that the python package exists in environment.\"\"\"\n",
        "\n",
        "\n",
        "        try:\n",
        "            values[\"client\"] = ChatModel.from_pretrained(values[\"model_name\"])\n",
        "        except AttributeError:\n",
        "            raise ValueError(\n",
        "                \"Could not set Vertex Text Model client.\"\n",
        "            )\n",
        "\n",
        "        return values\n",
        "\n",
        "    def _response_to_chat_results(\n",
        "        self, response: object, stop: Optional[List[str]]\n",
        "    ) -> ChatResult:\n",
        "        text = self._enforce_stop_words(response.text, stop)\n",
        "        return ChatResult(generations=[ChatGeneration(message=AIMessage(content=text))])\n",
        "\n",
        "class VertexChat(_VertexChatCommon, BaseChatModel):\n",
        "    \"\"\"Wrapper around Vertex AI large language models.\"\"\"\n",
        "\n",
        "    def _generate(\n",
        "        self, messages: List[BaseMessage], stop: Optional[List[str]] = None\n",
        "    ) -> ChatResult:\n",
        "        chat, prompt = self._start_chat(messages)\n",
        "        response = chat.send_message(prompt)\n",
        "        return self._response_to_chat_results(response, stop=stop)\n",
        "\n",
        "    def _start_chat(\n",
        "        self, messages: List[BaseMessage]\n",
        "    ) -> Tuple[object, str]:\n",
        "        \"\"\"Start a chat.\n",
        "        Args:\n",
        "            messages: a list of BaseMessage.\n",
        "        Returns:\n",
        "            a tuple that has a Vertex AI chat model initializes, and a prompt to send to the model.\n",
        "        Currently it expects either one HumanMessage, or two message (SystemMessage and HumanMessage).\n",
        "        If two messages are provided, the first one would be use for context.\n",
        "        \"\"\"\n",
        "        if len(messages) == 1:\n",
        "            message = messages[0]\n",
        "            if not isinstance(message, HumanMessage):\n",
        "                raise ValueError(\"Message should be from a human if it's the first one.\")\n",
        "            context, prompt = None, message.content\n",
        "        elif len(messages) == 2:\n",
        "            first_message, second_message = messages[0], messages[1]\n",
        "            if not isinstance(first_message, SystemMessage):\n",
        "                raise ValueError(\n",
        "                    \"The first message should be a system if there're two of them.\"\n",
        "                )\n",
        "            if not isinstance(second_message, HumanMessage):\n",
        "                raise ValueError(\"The second message should be from a human.\")\n",
        "            context, prompt = first_message.content, second_message.content\n",
        "        else:\n",
        "            raise ValueError(f\"Chat model expects only one or two messages. Received {len(messages)}\")\n",
        "        chat = self.client.start_chat(context=context, **self._default_params)\n",
        "        return chat, prompt\n",
        "\n",
        "    async def _agenerate(\n",
        "        self, messages: List[BaseMessage], stop: Optional[List[str]] = None\n",
        "    ) -> ChatResult:\n",
        "        raise NotImplementedError(\n",
        "            \"\"\"Vertex AI doesn't support async requests at the moment.\"\"\"\n",
        "        )\n",
        "\n",
        "\n",
        "class VertexMultiTurnChat(_VertexChatCommon, BaseChatModel):\n",
        "    \"\"\"Wrapper around Vertex AI large language models.\"\"\"\n",
        "\n",
        "    chat: Optional[object] = None\n",
        "\n",
        "    def clear_chat(self) -> None:\n",
        "        self.chat = None\n",
        "\n",
        "    def start_chat(self, message: Optional[SystemMessage] = None) -> None:\n",
        "        if self.chat:\n",
        "            raise ValueError(\"Chat has already been started. Please, clear it first.\")\n",
        "        if message and not isinstance(message, SystemMessage):\n",
        "            raise ValueError(\"Context should be a system message\")\n",
        "        context = message.content if message else None\n",
        "        self.chat = self.client.start_chat(context=context, **self._default_params)\n",
        "\n",
        "    @property\n",
        "    def history(self) -> List[Tuple[str]]:\n",
        "        \"\"\"Chat history.\"\"\"\n",
        "        if self.chat:\n",
        "            return self.chat._history\n",
        "        return []\n",
        "\n",
        "    def _generate(\n",
        "        self, messages: List[BaseMessage], stop: Optional[List[str]] = None\n",
        "    ) -> ChatResult:\n",
        "        if len(messages) != 1:\n",
        "            raise ValueError(\n",
        "                \"You should send exactly one message to the chat each turn.\"\n",
        "            )\n",
        "        if not self.chat:\n",
        "            raise ValueError(\"You should start_chat first!\")\n",
        "        response = self.chat.send_message(messages[0].content)\n",
        "        return self._response_to_chat_results(response, stop=stop)\n",
        "\n",
        "    async def _agenerate(\n",
        "        self, messages: List[BaseMessage], stop: Optional[List[str]] = None\n",
        "    ) -> ChatResult:\n",
        "        raise NotImplementedError(\n",
        "            \"\"\"Vertex AI doesn't support async requests at the moment.\"\"\"\n",
        "        )\n",
        "\n",
        "class VertexEmbeddings(Embeddings, BaseModel):\n",
        "    \"\"\"Wrapper around Vertex AI large language models embeddings API.\n",
        "    \"\"\"\n",
        "    model_name: str = \"textembedding-gecko@001\"\n",
        "    \"\"\"Model name to use.\"\"\"\n",
        "\n",
        "    model: Any\n",
        "    requests_per_minute: int = 15\n",
        "\n",
        "\n",
        "    @root_validator()\n",
        "    def validate_environment(cls, values: Dict) -> Dict:\n",
        "        \"\"\"Validate that the python package exists in environment.\"\"\"\n",
        "\n",
        "        try:\n",
        "            values[\"model\"] = TextEmbeddingModel\n",
        "\n",
        "        except AttributeError:\n",
        "            raise ValueError(\n",
        "                \"Could not set Vertex Text Model client.\"\n",
        "            )\n",
        "\n",
        "        return values\n",
        "\n",
        "    class Config:\n",
        "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
        "\n",
        "        extra = Extra.forbid\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "      \"\"\"Call Vertex LLM embedding endpoint for embedding docs\n",
        "      Args:\n",
        "          texts: The list of texts to embed.\n",
        "      Returns:\n",
        "          List of embeddings, one for each text.\n",
        "      \"\"\"\n",
        "      self.model = self.model.from_pretrained(self.model_name)\n",
        "\n",
        "      limiter = rate_limit(self.requests_per_minute)\n",
        "      results = []\n",
        "      docs = list(texts)\n",
        "\n",
        "      while docs:\n",
        "        # Working in batches of 2 because the API apparently won't let\n",
        "        # us send more than 2 documents per request to get embeddings.\n",
        "        head, docs = docs[:2], docs[2:]\n",
        "        # print(f'Sending embedding request for: {head!r}')\n",
        "        chunk = self.model.get_embeddings(head)\n",
        "        results.extend(chunk)\n",
        "        next(limiter)\n",
        "\n",
        "      return [r.values for r in results]\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "      \"\"\"Call Vertex LLM embedding endpoint for embedding query text.\n",
        "      Args:\n",
        "        text: The text to embed.\n",
        "      Returns:\n",
        "        Embedding for the text.\n",
        "      \"\"\"\n",
        "      single_result = self.embed_documents([text])\n",
        "      return single_result[0]\n",
        "\n",
        "#Initialize a model\n",
        "llm = VertexLLM(\n",
        "    model_name='text-bison@001',\n",
        "    max_output_tokens=256,\n",
        "    temperature=0,\n",
        "    top_p=0.8,top_k=40,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "pIuZ0ThX-oIk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create SQL engine for BigQuery"
      ],
      "metadata": {
        "id": "LqDhLithzJgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import *\n",
        "from sqlalchemy.engine import create_engine\n",
        "from sqlalchemy.schema import *\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NmRwdkm9Mm_u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_uri = f\"bigquery://{project_id}/{dataset_id}\"\n",
        "engine = create_engine(f\"bigquery://{project_id}/{dataset_id}\")"
      ],
      "metadata": {
        "id": "nBzy1sV51h1e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing all tables\n",
        "query=f\"\"\"SELECT * FROM {project_id}.{dataset_id}.{table_name1}\"\"\"\n",
        "engine.execute(query).first()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_8Jr90a104A",
        "outputId": "2c40145f-1174-4d15-f522-a51030acde5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6a25d099e509>:3: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  engine.execute(query).first()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(datetime.datetime(2023, 9, 20, 0, 0, tzinfo=<UTC>), '2023-09-20:ES:1604:341:product', 341, 625, 'ES', 1604, 'VELILLA', '12603741013067105977', 1604, 'Ropa y accesorios > Prendas de vestir', 'es-ES', 'Mono Velilla', Decimal('21.000000000'), Decimal('23.000000000'), 'EUR', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing', 'Apparel & Accessories', 'Clothing', None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQL Chain setup for LLM"
      ],
      "metadata": {
        "id": "mpW-rMVI0DUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import SQLDatabase, SQLDatabaseChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "def bq_qna(question):\n",
        "  #create SQLDatabase instance from BQ engine\n",
        "  # db = SQLDatabase(engine=engine,metadata=MetaData(bind=engine),include_tables=[x for x in table_names])\n",
        "  db = SQLDatabase(engine=engine,metadata=MetaData(bind=engine),include_tables=[table_name1])\n",
        "  #create SQL DB Chain with the initialized LLM and above SQLDB instance\n",
        "  db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, return_intermediate_steps=True)\n",
        "\n",
        "  #Define prompt for BigQuery SQL\n",
        "  _googlesql_prompt = \"\"\"You are a GoogleSQL expert. Given an input question, first create a syntactically correct GoogleSQL query to run, then look at the results of the query and return the answer to the input question.\n",
        "  Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per GoogleSQL. You can order the results to return the most informative data in the database.\n",
        "  Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
        "  Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
        "  Use the following format:\n",
        "  Question: \"Question here\"\n",
        "  SQLQuery: \"SQL Query to run\"\n",
        "  SQLResult: \"Result of the SQLQuery\"\n",
        "  Answer: \"Final answer here\"\n",
        "  Only use the following tables:\n",
        "  {table_info}\n",
        "\n",
        "  If someone asks for aggregation on a STRING data type column, then CAST column as NUMERIC before you do the aggregation.\n",
        "\n",
        "  If someone asks for specific month, use ActivityDate between current month's start date and current month's end date\n",
        "\n",
        "  If someone asks for column names in the table, use the following format:\n",
        "  SELECT column_name\n",
        "  FROM `{project_id}.{dataset_id}`.INFORMATION_SCHEMA.COLUMNS\n",
        "  WHERE table_name in {table_info}\n",
        "\n",
        "  Question: {input}\"\"\"\n",
        "\n",
        "  GOOGLESQL_PROMPT = PromptTemplate(\n",
        "      input_variables=[\"input\", \"table_info\", \"top_k\", \"project_id\", \"dataset_id\"],\n",
        "      template=_googlesql_prompt,\n",
        "  )\n",
        "\n",
        "  #passing question to the prompt template\n",
        "  final_prompt = GOOGLESQL_PROMPT.format(input=question, project_id =project_id, dataset_id=dataset_id, table_info=table_names, top_k=10000)\n",
        "\n",
        "  #pass final prompt to SQL Chain\n",
        "  output = db_chain(final_prompt)\n",
        "\n",
        "\n",
        "  return output['result'], output['intermediate_steps'][1]\n"
      ],
      "metadata": {
        "id": "7JmfJcgP5EhU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the setup"
      ],
      "metadata": {
        "id": "LAlVAHPe16Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing 1\n",
        "bq_qna('Show me the top 10 product with category_2 equal to Clothing with the best ranking')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5wmsihBD4tS",
        "outputId": "b7580c66-8f57-4af9-f57a-0e8838abe324"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "You are a GoogleSQL expert. Given an input question, first create a syntactically correct GoogleSQL query to run, then look at the results of the query and return the answer to the input question.\n",
            "  Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per GoogleSQL. You can order the results to return the most informative data in the database.\n",
            "  Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
            "  Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
            "  Use the following format:\n",
            "  Question: \"Question here\"\n",
            "  SQLQuery: \"SQL Query to run\"\n",
            "  SQLResult: \"Result of the SQLQuery\"\n",
            "  Answer: \"Final answer here\"\n",
            "  Only use the following tables:\n",
            "  bestsellers_ES_limit_1M\n",
            "\n",
            "  If someone asks for aggregation on a STRING data type column, then CAST column as NUMERIC before you do the aggregation.\n",
            "\n",
            "  If someone asks for specific month, use ActivityDate between current month's start date and current month's end date\n",
            "\n",
            "  If someone asks for column names in the table, use the following format:\n",
            "  SELECT column_name\n",
            "  FROM `cheese-389814.bestsellers`.INFORMATION_SCHEMA.COLUMNS\n",
            "  WHERE table_name in bestsellers_ES_limit_1M\n",
            "\n",
            "  Question: Show me the top 10 product with category_2 equal to Clothing with the best ranking\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT product_title_name, price_range_min, price_range_max, price_range_currency, image_url_gcs, image_url, page_url, brand_style, brand_age, sub_category, material, shape, color, size, style, use, feature, print, pattern, affinity, silhouette, neckline, sleeve, design, occasion, waist, hem_style, fit, leg_style, sandal_style, theme, cushion_color, cushion_type, frame, pieces, chair_type, roof_type, pendant_type, chain_type, motif, inscription, stone_size, character, finish, ingredient, volume, flavor, texture, spf, formula, form, color_couunt, google_product_category_name, category_1, category_2, category_3, category_4, category_5\n",
            "FROM bestsellers_ES_limit_1M\n",
            "WHERE category_2 = 'Clothing'\n",
            "ORDER BY rank DESC\n",
            "LIMIT 10\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[('C&A 2 PACK Pijama Mujer', Decimal('17.000000000'), Decimal('18.000000000'), 'EUR', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Sleepwear & Loungewear > Pajamas', 'Apparel & Accessories', 'Clothing', 'Sleepwear & Loungewear', 'Pajamas', 'Pajamas'), ('Cazadora tipo bomber de hombros caídos de color combinado cuero PU', Decimal('29.000000000'), Decimal('29.000000000'), 'EUR', None, None, None, None, None, None, 'faux leather', None, None, None, None, None, None, None, None, 'boys', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Outerwear > Coats & Jackets', 'Apparel & Accessories', 'Clothing', 'Outerwear', 'Coats & Jackets', 'Coats & Jackets'), ('Chaqueta Patagonia Torrentshell 3L Hombre', Decimal('131.000000000'), Decimal('200.000000000'), 'EUR', None, None, None, None, None, 'costume', 'peacoat', None, None, 's', 'jacket', None, None, None, None, 'men', None, None, None, None, 'running', None, None, 'cropped', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Outerwear > Coats & Jackets', 'Apparel & Accessories', 'Clothing', 'Outerwear', 'Coats & Jackets', 'Coats & Jackets'), ('Pantalón De Caza Hombre Solognac Steppe 300 Verde Resistente Multibolsillos', Decimal('20.000000000'), Decimal('21.000000000'), 'EUR', None, None, None, None, None, 'track', 'jersey', None, 'verde', None, 'hiking', None, None, None, None, 'men', None, None, None, None, 'hunting', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Pants', 'Apparel & Accessories', 'Clothing', 'Pants', None, None), ('Camiseta Original Hombre Basic 2 long Pepe Jeans', Decimal('10.000000000'), Decimal('26.000000000'), 'EUR', None, None, None, None, None, 't shirt', 'jersey', None, None, None, 'jersey', None, None, None, None, 'men', None, 'round neck', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Shirts & Tops', 'Apparel & Accessories', 'Clothing', 'Shirts & Tops', None, None), ('Bershka Abrigo Parka Capucha Algodón Mujer', Decimal('35.000000000'), Decimal('51.000000000'), 'EUR', None, None, None, None, None, 'suit', 'cotton', None, None, None, 'hoodie', None, None, None, None, 'women', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Outerwear > Coats & Jackets', 'Apparel & Accessories', 'Clothing', 'Outerwear', 'Coats & Jackets', 'Coats & Jackets'), ('hombre Sudaderas con capucha Nike', Decimal('45.000000000'), Decimal('46.000000000'), 'EUR', None, 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTgL9j0QvcIZ9KV4uuTPJU-jHTAxbWOnxobEg&usqp=CAU', 'https://www.nike.com/es/t/forward-hoodie-sudadera-con-capucha-lxG0Zn', None, None, 'hoodie', None, None, None, None, 'hoodie', None, None, None, None, 'men', None, 'hoodie', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Shirts & Tops', 'Apparel & Accessories', 'Clothing', 'Shirts & Tops', None, None), ('unicolor Top muslo con abertura Falda', None, None, 'EUR', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Outfit Sets', 'Apparel & Accessories', 'Clothing', 'Outfit Sets', None, None), ('Hummel Mujer Pantalones Cortos Core XK POLY', Decimal('14.000000000'), Decimal('20.000000000'), 'EUR', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Shorts', 'Apparel & Accessories', 'Clothing', 'Shorts', None, None), ('Bershka Cazadora Doble Faz Efecto Piel Mujer', Decimal('50.000000000'), Decimal('51.000000000'), 'EUR', None, None, None, None, None, None, 'double knit', None, None, None, None, None, None, None, None, 'women', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'Apparel & Accessories > Clothing > Outerwear > Coats & Jackets', 'Apparel & Accessories', 'Clothing', 'Outerwear', 'Coats & Jackets', 'Coats & Jackets')]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mThe top 10 products with category_2 equal to Clothing with the best ranking are:\n",
            "\n",
            "1. C&A 2 PACK Pijama Mujer\n",
            "2. Cazadora tipo bomber de hombros caídos de color combinado cuero PU\n",
            "3. Chaqueta Patagonia Torrentshell 3L Hombre\n",
            "4. Pantalón De Caza Hombre Solognac Steppe 300 Verde Resistente Multibolsillos\n",
            "5. Camiseta Original Hombre Basic 2 long Pepe Jeans\n",
            "6. Bershka Abrigo Parka Capucha Algodón Mujer\n",
            "7. hombre Sudaderas con capucha Nike\n",
            "8. unicolor Top muslo con abertura Falda\n",
            "9. Hummel Mujer Pantalones Cortos Core XK POLY\n",
            "10. Bershka Cazadora Doble Faz Efecto Piel Mujer\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The top 10 products with category_2 equal to Clothing with the best ranking are:\\n\\n1. C&A 2 PACK Pijama Mujer\\n2. Cazadora tipo bomber de hombros caídos de color combinado cuero PU\\n3. Chaqueta Patagonia Torrentshell 3L Hombre\\n4. Pantalón De Caza Hombre Solognac Steppe 300 Verde Resistente Multibolsillos\\n5. Camiseta Original Hombre Basic 2 long Pepe Jeans\\n6. Bershka Abrigo Parka Capucha Algodón Mujer\\n7. hombre Sudaderas con capucha Nike\\n8. unicolor Top muslo con abertura Falda\\n9. Hummel Mujer Pantalones Cortos Core XK POLY\\n10. Bershka Cazadora Doble Faz Efecto Piel Mujer',\n",
              " \"SELECT product_title_name, price_range_min, price_range_max, price_range_currency, image_url_gcs, image_url, page_url, brand_style, brand_age, sub_category, material, shape, color, size, style, use, feature, print, pattern, affinity, silhouette, neckline, sleeve, design, occasion, waist, hem_style, fit, leg_style, sandal_style, theme, cushion_color, cushion_type, frame, pieces, chair_type, roof_type, pendant_type, chain_type, motif, inscription, stone_size, character, finish, ingredient, volume, flavor, texture, spf, formula, form, color_couunt, google_product_category_name, category_1, category_2, category_3, category_4, category_5\\nFROM bestsellers_ES_limit_1M\\nWHERE category_2 = 'Clothing'\\nORDER BY rank DESC\\nLIMIT 10\")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing 2\n",
        "bq_qna('Show me the top 10 product with category_2 equal to Clothing with the best ranking, include price_range y la image_url')"
      ],
      "metadata": {
        "id": "-ypFevIgGNl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing 3 - Metadata queries\n",
        "bq_qna('what are the product name with greatest price')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78z0zs8cLdJ0",
        "outputId": "fdf5de63-fc68-4838-ddde-d58d27724a09"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "You are a GoogleSQL expert. Given an input question, first create a syntactically correct GoogleSQL query to run, then look at the results of the query and return the answer to the input question.\n",
            "  Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per GoogleSQL. You can order the results to return the most informative data in the database.\n",
            "  Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
            "  Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
            "  Use the following format:\n",
            "  Question: \"Question here\"\n",
            "  SQLQuery: \"SQL Query to run\"\n",
            "  SQLResult: \"Result of the SQLQuery\"\n",
            "  Answer: \"Final answer here\"\n",
            "  Only use the following tables:\n",
            "  bestsellers_ES_limit_1M\n",
            "\n",
            "  If someone asks for aggregation on a STRING data type column, then CAST column as NUMERIC before you do the aggregation.\n",
            "\n",
            "  If someone asks for specific month, use ActivityDate between current month's start date and current month's end date\n",
            "\n",
            "  If someone asks for column names in the table, use the following format:\n",
            "  SELECT column_name\n",
            "  FROM `cheese-389814.bestsellers`.INFORMATION_SCHEMA.COLUMNS\n",
            "  WHERE table_name in bestsellers_ES_limit_1M\n",
            "\n",
            "  Question: what are the product name with greatest price\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT product_title_name\n",
            "FROM bestsellers_ES_limit_1M\n",
            "ORDER BY price_range_max DESC\n",
            "LIMIT 1\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[('Chaqueta Dainese Air Tex',)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mChaqueta Dainese Air Tex\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Chaqueta Dainese Air Tex',\n",
              " 'SELECT product_title_name\\nFROM bestsellers_ES_limit_1M\\nORDER BY price_range_max DESC\\nLIMIT 1')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing 4 - Joins\n",
        "bq_qna('what are the product name with greatest price, include the price min and max')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNL16fEJMo2b",
        "outputId": "8d7e87c8-815a-45e1-d638-c314484bdf41"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "You are a GoogleSQL expert. Given an input question, first create a syntactically correct GoogleSQL query to run, then look at the results of the query and return the answer to the input question.\n",
            "  Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per GoogleSQL. You can order the results to return the most informative data in the database.\n",
            "  Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
            "  Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
            "  Use the following format:\n",
            "  Question: \"Question here\"\n",
            "  SQLQuery: \"SQL Query to run\"\n",
            "  SQLResult: \"Result of the SQLQuery\"\n",
            "  Answer: \"Final answer here\"\n",
            "  Only use the following tables:\n",
            "  bestsellers_ES_limit_1M\n",
            "\n",
            "  If someone asks for aggregation on a STRING data type column, then CAST column as NUMERIC before you do the aggregation.\n",
            "\n",
            "  If someone asks for specific month, use ActivityDate between current month's start date and current month's end date\n",
            "\n",
            "  If someone asks for column names in the table, use the following format:\n",
            "  SELECT column_name\n",
            "  FROM `cheese-389814.bestsellers`.INFORMATION_SCHEMA.COLUMNS\n",
            "  WHERE table_name in bestsellers_ES_limit_1M\n",
            "\n",
            "  Question: what are the product name with greatest price, include the price min and max\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT product_title_name, price_range_min, price_range_max FROM bestsellers_ES_limit_1M ORDER BY price_range_max DESC LIMIT 1\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[('Chaqueta Dainese Air Tex', Decimal('137.000000000'), Decimal('546.000000000'))]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mThe product with the greatest price is Chaqueta Dainese Air Tex, with a price range of 137.00 to 546.00.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The product with the greatest price is Chaqueta Dainese Air Tex, with a price range of 137.00 to 546.00.',\n",
              " 'SELECT product_title_name, price_range_min, price_range_max FROM bestsellers_ES_limit_1M ORDER BY price_range_max DESC LIMIT 1')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing 5 - Joins\n",
        "bq_qna(\"\"\"show me the url to the product name Velilla Mono\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1aSee4pM886",
        "outputId": "a8dda909-c834-434a-ec3a-b33bfbf1a08e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "You are a GoogleSQL expert. Given an input question, first create a syntactically correct GoogleSQL query to run, then look at the results of the query and return the answer to the input question.\n",
            "  Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per GoogleSQL. You can order the results to return the most informative data in the database.\n",
            "  Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
            "  Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
            "  Use the following format:\n",
            "  Question: \"Question here\"\n",
            "  SQLQuery: \"SQL Query to run\"\n",
            "  SQLResult: \"Result of the SQLQuery\"\n",
            "  Answer: \"Final answer here\"\n",
            "  Only use the following tables:\n",
            "  bestsellers_ES_limit_1M\n",
            "\n",
            "  If someone asks for aggregation on a STRING data type column, then CAST column as NUMERIC before you do the aggregation.\n",
            "\n",
            "  If someone asks for specific month, use ActivityDate between current month's start date and current month's end date\n",
            "\n",
            "  If someone asks for column names in the table, use the following format:\n",
            "  SELECT column_name\n",
            "  FROM `cheese-389814.bestsellers`.INFORMATION_SCHEMA.COLUMNS\n",
            "  WHERE table_name in bestsellers_ES_limit_1M\n",
            "\n",
            "  Question: show me the url to the product name Velilla Mono\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT page_url FROM bestsellers_ES_limit_1M WHERE product_title_name = 'Mono Velilla'\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(None,), (None,), (None,), (None,)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mNone\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('None',\n",
              " \"SELECT page_url FROM bestsellers_ES_limit_1M WHERE product_title_name = 'Mono Velilla'\")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing 5 - Joins\n",
        "bq_qna(\"\"\"show me the url to the products barnd exact Velilla with date 8 Aug 2023\"\"\")"
      ],
      "metadata": {
        "id": "Rw70AMV2OfuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UI for Demo"
      ],
      "metadata": {
        "id": "9Hj4JSWf2JKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ## Ask BiqQuery\n",
        "\n",
        "    This demo is to showcase answering questions on a tabular data available in Big Query using Vertex PALM LLM & Langchain.\n",
        "\n",
        "    This demo uses a sample public dataset from Kaggle (https://www.kaggle.com/datasets/arashnic/fitbit)\n",
        "\n",
        "    ### Sample Inputs:\n",
        "    1. Show me the top 10 product with category_2 equal to Clothing with the best ranking, include price_range y la image_url ?\n",
        "    2. what are the product name with greatest price, include the price min and max ?\n",
        "    3. show me the url to the products barnd exact Velilla with date 8 Aug 2023\n",
        "\n",
        "    ### Enter a search query...\n",
        "\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        input_text = gr.Textbox(label=\"Question\", placeholder=\"Show me the top 10 product with category_2 equal to Clothing with the best ranking\")\n",
        "\n",
        "    with gr.Row():\n",
        "      generate = gr.Button(\"Ask BigQuery\")\n",
        "\n",
        "    with gr.Row():\n",
        "      label2 = gr.Textbox(label=\"Output\")\n",
        "    with gr.Row():\n",
        "      label3 = gr.Textbox(label=\"SQL query generated by LLM\")\n",
        "\n",
        "    generate.click(bq_qna,input_text, [label2, label3])\n",
        "demo.launch(share=False, debug=False)"
      ],
      "metadata": {
        "id": "SGyd67aqXfLV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "f4b7400b-1cb1-401d-b7f0-cdcc710f09aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}